{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Query Retrieval\n",
    "\n",
    "This method can automatically use a ChatModel to make slight variations of your initial query to help attempt overcome any issues with cosine similarity distances, this allows you to phrase things more like a general query question rather than a pure document similarity look-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain.document_loaders import WikipediaLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/genai/lib/python3.11/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /opt/homebrew/Caskroom/miniconda/base/envs/genai/lib/python3.11/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of all the documents - 24\n"
     ]
    }
   ],
   "source": [
    "# Search Wikipedia and load relevant documents.. Each page is considered as a single document.\n",
    "loader = WikipediaLoader(query='MKUltra')\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Length of all the documents - {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 525, which is longer than the specified 500\n",
      "Created a chunk of size 588, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "# Split into chunks\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500)\n",
    "docs = text_splitter.split_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI for Embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the persistent ChromaDB\n",
    "db = Chroma.from_documents(documents=docs,embedding=embeddings,persist_directory='some_data/mk_utra/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ChatModel for MultiQuery\n",
    "question = \"When was this declassified?\"\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(retriever=db.as_retriever(), llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging for the queries\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger('langchain.retrievers.multi_query').setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. What is the date of the declassification of this information?', '2. Can you provide the timeline for when this was declassified?', '3. At what point in time was this information made public?']\n"
     ]
    }
   ],
   "source": [
    "unique_docs = retriever_from_llm.invoke(input=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the Generated queries - 7\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of the returned topics - {len(unique_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Background ==\n",
      "In 1974, a New York Times article was published that accused the CIA of illegal operations committed against US citizens. Authored by Seymour M. Hersh, it documented an intelligence operation against the anti-war movement, as well as \"break-ins, wiretapping and the surreptitious inspection of mail\" conducted since the 1950s. According to former CIA Official Cord Meyer, these disclosures \"Convinced large sections of the American public that the CIA had become a domestic Gestapo and stimulated an overwhelming demand for the wide-ranging congressional investigations that were to follow.\"\n",
      "Hersh had been tipped off to the possibility of an \"in house operation\" by an unidentified member of the CIA in spring of 1974. He embarked on an investigation, speaking to sources that included CIA Chief of Counterintelligence James Angleton. Although he was not aware of its existence, Hersh uncovered much information that had been documented in the \"Family Jewels\", a report ordered by Director of Central Intelligence William Colby that chronicled CIA abuses over the past 25 years. The report would not be formally revealed to the public until 2007.\n",
      "\n",
      "\n",
      "=== Monitoring of anti-war movement and Project MINARET ===\n",
      "\n",
      "The article alleged that CIA agents had followed and photographed participants in the antiwar movement, as well as other demonstrations. It also reported that the CIA \"set up a network of informants who were ordered to penetrate antiwar groups\", and even placed an avowedly anti-war congressperson under surveillance while putting other lawmakers in a dossier on dissident Americans.\n",
      "Instituted in 1967 by the NSA, Project MINARET's purpose was to document \"Soviet, Chinese, and North Vietnamese influence over the militant civil rights and antiâ€“Vietnam War movements\" for the CIA and FBI, according to historian Donald Critchlow. The NSA provided CIA and FBI officials  with reports of intercepted international communications by certain individuals in these movements. NSA officials stipulated that FBI and CIA agents must destroy or return these reports within two weeks of receiving them. The NSA also required that \"the reports not be 'identified with the National Security Agency' and that all records relating to this program were 'not serialize[d]' or filed with other NSA records, were classified 'Top Secret,' and were stamped 'Background Use Only'... because the\n"
     ]
    }
   ],
   "source": [
    "print(unique_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
