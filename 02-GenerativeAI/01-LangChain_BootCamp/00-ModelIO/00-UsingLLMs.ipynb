{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Large Language Models\n",
    "\n",
    "## Working with Text Models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T12:29:24.837082Z",
     "start_time": "2025-07-09T12:29:24.351610Z"
    }
   },
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "from langchain_openai import OpenAI"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that LangChain automatically looks up for any environment variable with the name OPENAI_API_KEY automatically when making a connection to OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T12:29:36.739347Z",
     "start_time": "2025-07-09T12:29:36.551724Z"
    }
   },
   "source": [
    "# Initialize the Text Model\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = OpenAI(openai_api_key = api_key)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T12:29:56.511487Z",
     "start_time": "2025-07-09T12:29:53.744088Z"
    }
   },
   "source": [
    "# Lets work on a simplest way to get a text autocomplete -\n",
    "print(llm.invoke(\"Here is a fun fact about Pluto Planet :\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "Pluto was discovered in 1930 by American astronomer Clyde Tombaugh at the Lowell Observatory in Flagstaff, Arizona. It was the first planet to be discovered in the modern era.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T12:30:07.279378Z",
     "start_time": "2025-07-09T12:30:03.127401Z"
    }
   },
   "source": [
    "# Lets generate a full output with mmore information\n",
    "result = llm.generate([\"Here is Fun Fact about Pluto : \",\n",
    "                       \"Here is a Fun Fact about Mars :\"])\n",
    "\n",
    "# to check the schema of the response\n",
    "result.model_json_schema()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$defs': {'BaseMessage': {'additionalProperties': True,\n",
       "   'description': 'Base abstract message class.\\n\\nMessages are the inputs and outputs of ChatModels.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'title': 'Type', 'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content', 'type'],\n",
       "   'title': 'BaseMessage',\n",
       "   'type': 'object'},\n",
       "  'BaseMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Message chunk, which can be concatenated with other Message chunks.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'title': 'Type', 'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content', 'type'],\n",
       "   'title': 'BaseMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'ChatGeneration': {'description': 'A single chat generation output.\\n\\nA subclass of Generation that represents the response from a chat model\\nthat generates chat messages.\\n\\nThe `message` attribute is a structured representation of the chat message.\\nMost of the time, the message will be of type `AIMessage`.\\n\\nUsers working with chat models will usually access information via either\\n`AIMessage` (returned from runnable interfaces) or `LLMResult` (available\\nvia callbacks).',\n",
       "   'properties': {'text': {'default': '', 'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'anyOf': [{'additionalProperties': True,\n",
       "       'type': 'object'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Generation Info'},\n",
       "    'type': {'const': 'ChatGeneration',\n",
       "     'default': 'ChatGeneration',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'message': {'$ref': '#/$defs/BaseMessage'}},\n",
       "   'required': ['message'],\n",
       "   'title': 'ChatGeneration',\n",
       "   'type': 'object'},\n",
       "  'ChatGenerationChunk': {'description': 'ChatGeneration chunk.\\n\\nChatGeneration chunks can be concatenated with other ChatGeneration chunks.',\n",
       "   'properties': {'text': {'default': '', 'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'anyOf': [{'additionalProperties': True,\n",
       "       'type': 'object'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Generation Info'},\n",
       "    'type': {'const': 'ChatGenerationChunk',\n",
       "     'default': 'ChatGenerationChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'message': {'$ref': '#/$defs/BaseMessageChunk'}},\n",
       "   'required': ['message'],\n",
       "   'title': 'ChatGenerationChunk',\n",
       "   'type': 'object'},\n",
       "  'Generation': {'description': 'A single text generation output.\\n\\nGeneration represents the response from an \"old-fashioned\" LLM that\\ngenerates regular text (not chat messages).\\n\\nThis model is used internally by chat model and will eventually\\nbe mapped to a more general `LLMResult` object, and then projected into\\nan `AIMessage` object.\\n\\nLangChain users working with chat models will usually access information via\\n`AIMessage` (returned from runnable interfaces) or `LLMResult` (available\\nvia callbacks). Please refer the `AIMessage` and `LLMResult` schema documentation\\nfor more information.',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'anyOf': [{'additionalProperties': True,\n",
       "       'type': 'object'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Generation Info'},\n",
       "    'type': {'const': 'Generation',\n",
       "     'default': 'Generation',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'}},\n",
       "   'required': ['text'],\n",
       "   'title': 'Generation',\n",
       "   'type': 'object'},\n",
       "  'GenerationChunk': {'description': 'Generation chunk, which can be concatenated with other Generation chunks.',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'anyOf': [{'additionalProperties': True,\n",
       "       'type': 'object'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Generation Info'},\n",
       "    'type': {'const': 'Generation',\n",
       "     'default': 'Generation',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'}},\n",
       "   'required': ['text'],\n",
       "   'title': 'GenerationChunk',\n",
       "   'type': 'object'},\n",
       "  'RunInfo': {'description': 'Class that contains metadata for a single execution of a Chain or model.\\n\\nDefined for backwards compatibility with older versions of langchain_core.\\n\\nThis model will likely be deprecated in the future.\\n\\nUsers can acquire the run_id information from callbacks or via run_id\\ninformation present in the astream_event API (depending on the use case).',\n",
       "   'properties': {'run_id': {'format': 'uuid',\n",
       "     'title': 'Run Id',\n",
       "     'type': 'string'}},\n",
       "   'required': ['run_id'],\n",
       "   'title': 'RunInfo',\n",
       "   'type': 'object'}},\n",
       " 'description': 'A container for results of an LLM call.\\n\\nBoth chat models and LLMs generate an LLMResult object. This object contains\\nthe generated outputs and any additional information that the model provider\\nwants to return.',\n",
       " 'properties': {'generations': {'items': {'items': {'anyOf': [{'$ref': '#/$defs/Generation'},\n",
       "      {'$ref': '#/$defs/ChatGeneration'},\n",
       "      {'$ref': '#/$defs/GenerationChunk'},\n",
       "      {'$ref': '#/$defs/ChatGenerationChunk'}]},\n",
       "    'type': 'array'},\n",
       "   'title': 'Generations',\n",
       "   'type': 'array'},\n",
       "  'llm_output': {'anyOf': [{'additionalProperties': True, 'type': 'object'},\n",
       "    {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'title': 'Llm Output'},\n",
       "  'run': {'anyOf': [{'items': {'$ref': '#/$defs/RunInfo'}, 'type': 'array'},\n",
       "    {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'title': 'Run'},\n",
       "  'type': {'const': 'LLMResult',\n",
       "   'default': 'LLMResult',\n",
       "   'title': 'Type',\n",
       "   'type': 'string'}},\n",
       " 'required': ['generations'],\n",
       " 'title': 'LLMResult',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T12:30:21.896520Z",
     "start_time": "2025-07-09T12:30:21.893809Z"
    }
   },
   "source": [
    "# Check the detailed response\n",
    "response = result.generations\n",
    "print(response[0][0].text)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Pluto was discovered in 1930 by American astronomer Clyde Tombaugh. It was considered the ninth planet in our solar system until 2006 when it was reclassified as a \"dwarf planet.\"\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T12:30:27.079181Z",
     "start_time": "2025-07-09T12:30:27.075041Z"
    }
   },
   "source": [
    "# Check the token usage and other details about output of the LLM\n",
    "\n",
    "result.llm_output"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 78,\n",
       "  'total_tokens': 94,\n",
       "  'prompt_tokens': 16},\n",
       " 'model_name': 'gpt-3.5-turbo-instruct'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T12:30:38.943673Z",
     "start_time": "2025-07-09T12:30:38.895103Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "chat = ChatOpenAI(openai_api_key = api_key)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T12:31:03.931026Z",
     "start_time": "2025-07-09T12:31:02.032391Z"
    }
   },
   "source": [
    "# now lets ask a question\n",
    "result = chat.invoke([HumanMessage(content=\"Can you tell me a fact about Earth ?\")])\n",
    "result"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! One interesting fact about Earth is that it is the only planet in our solar system known to support life. Its unique combination of atmosphere, temperature, and water make it the perfect environment for a wide variety of living organisms to thrive.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 16, 'total_tokens': 64, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BrOEx6dYa63rYVc5akXjygWg4Lcls', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e678f7da-99df-45d4-98d8-99727d695548-0', usage_metadata={'input_tokens': 16, 'output_tokens': 48, 'total_tokens': 64, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T12:31:06.070621Z",
     "start_time": "2025-07-09T12:31:06.067346Z"
    }
   },
   "source": [
    "# Get the text response\n",
    "result.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! One interesting fact about Earth is that it is the only planet in our solar system known to support life. Its unique combination of atmosphere, temperature, and water make it the perfect environment for a wide variety of living organisms to thrive.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T12:31:17.469952Z",
     "start_time": "2025-07-09T12:31:14.998144Z"
    }
   },
   "source": [
    "# Lets try another\n",
    "result = chat.generate([[SystemMessage(content=\"You are a University Professor\"),\n",
    "                         HumanMessage(content=\"Can you tell me a fact about Earth ?\")]])\n",
    "\n",
    "result.generations[0][0].text"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! One interesting fact about Earth is that it is the only planet in our solar system known to have liquid water on its surface. This unique feature allows Earth to support a wide variety of life forms.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Temperature is a parameter that controls the “creativity” or randomness of the text generated by open ai llm. A higher temperature (e.g., 0.7) results in more diverse and creative output, while a lower temperature (e.g., 0.2) makes the output more deterministic and focused.\n",
    "\n",
    "- In practice, temperature affects the probability distribution over the possible tokens at each step of the generation process. A temperature of 0 would make the model completely deterministic, always choosing the most likely token."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T12:31:49.148781Z",
     "start_time": "2025-07-09T12:31:46.814490Z"
    }
   },
   "source": [
    "# We can add some extra parameters and args - here we are adding some extreme values\n",
    "result = chat.invoke([HumanMessage(content=\"Can you tell me a fact about Earth ?\")],\n",
    "                     temperature=2, max_tokens=100)\n",
    "result.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The coldest temperature ever recorded on Earth was minus 128.6 degrees Fahrenheit (minus 89.2 degrees Celsius) at Antarctica's Vostok station on July 21, 1983.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching\n",
    "\n",
    "Should only do this if the prompt is the exact same and the historical replies are okay to return."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T12:32:50.396518Z",
     "start_time": "2025-07-09T12:32:50.174034Z"
    }
   },
   "source": [
    "import langchain\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "# Initialize the cache\n",
    "langchain.llm_cache = InMemoryCache()"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T12:32:57.476939Z",
     "start_time": "2025-07-09T12:32:53.683079Z"
    }
   },
   "source": [
    "# The first time it is not in cache and hence might take little time\n",
    "print(llm.invoke(\"Tell me fact about Mars\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Mars is the fourth planet from the sun in our solar system, and is often referred to as the \"Red Planet\" due to its reddish appearance.\n",
      "\n",
      "2. Mars has a thin atmosphere composed mainly of carbon dioxide, with traces of other gases such as nitrogen and argon.\n",
      "\n",
      "3. The surface of Mars is covered in a variety of geological features, including volcanoes, canyons, and impact craters.\n",
      "\n",
      "4. The largest volcano in the solar system, Olympus Mons, is located on Mars and stands at a height of 22 km (13.6 miles).\n",
      "\n",
      "5. Mars has two small moons, Phobos and Deimos, which are irregularly shaped and are thought to be captured asteroids.\n",
      "\n",
      "6. The average temperature on Mars is -80 degrees Fahrenheit (-62 degrees Celsius), making it a very cold planet.\n",
      "\n",
      "7. The Martian day, or \"sol,\" is slightly longer than Earth's, at 24 hours and 39 minutes.\n",
      "\n",
      "8. Evidence suggests that Mars may have once had a much thicker atmosphere and flowing water on its surface, leading some scientists to believe that life may have once existed on the planet.\n",
      "\n",
      "9. NASA's Curiosity rover has been exploring the surface of Mars since 2012, providing valuable data and\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T12:33:01.585911Z",
     "start_time": "2025-07-09T12:33:01.582938Z"
    }
   },
   "source": [
    "# This response should come very fast\n",
    "print(llm.invoke(\"Tell me fact about Mars\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Mars is the fourth planet from the sun in our solar system, and is often referred to as the \"Red Planet\" due to its reddish appearance.\n",
      "\n",
      "2. Mars has a thin atmosphere composed mainly of carbon dioxide, with traces of other gases such as nitrogen and argon.\n",
      "\n",
      "3. The surface of Mars is covered in a variety of geological features, including volcanoes, canyons, and impact craters.\n",
      "\n",
      "4. The largest volcano in the solar system, Olympus Mons, is located on Mars and stands at a height of 22 km (13.6 miles).\n",
      "\n",
      "5. Mars has two small moons, Phobos and Deimos, which are irregularly shaped and are thought to be captured asteroids.\n",
      "\n",
      "6. The average temperature on Mars is -80 degrees Fahrenheit (-62 degrees Celsius), making it a very cold planet.\n",
      "\n",
      "7. The Martian day, or \"sol,\" is slightly longer than Earth's, at 24 hours and 39 minutes.\n",
      "\n",
      "8. Evidence suggests that Mars may have once had a much thicker atmosphere and flowing water on its surface, leading some scientists to believe that life may have once existed on the planet.\n",
      "\n",
      "9. NASA's Curiosity rover has been exploring the surface of Mars since 2012, providing valuable data and\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
