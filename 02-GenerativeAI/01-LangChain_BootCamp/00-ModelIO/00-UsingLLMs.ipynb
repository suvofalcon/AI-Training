{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Large Language Models\n",
    "\n",
    "## Working with Text Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that LangChain automatically looks up for any environment variable with the name OPENAI_API_KEY automatically when making a connection to OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Text Model\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = OpenAI(openai_api_key = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Pluto is named after the Roman god of the underworld, who could make himself invisible. The planet was named by 11-year-old British schoolgirl Venetia Burney in 1930, after it was discovered by astronomer Clyde W. Tombaugh.\n"
     ]
    }
   ],
   "source": [
    "# Lets work on a simplest way to get a text autocomplete -\n",
    "print(llm.invoke(\"Here is a fun fact about Pluto Planet :\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$defs': {'BaseMessage': {'additionalProperties': True,\n",
       "   'description': 'Base abstract message class.\\n\\nMessages are the inputs and outputs of ChatModels.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type', 'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content', 'type'],\n",
       "   'title': 'BaseMessage',\n",
       "   'type': 'object'},\n",
       "  'BaseMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Message chunk, which can be concatenated with other Message chunks.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type', 'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content', 'type'],\n",
       "   'title': 'BaseMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'ChatGeneration': {'description': 'A single chat generation output.\\n\\nA subclass of Generation that represents the response from a chat model\\nthat generates chat messages.\\n\\nThe `message` attribute is a structured representation of the chat message.\\nMost of the time, the message will be of type `AIMessage`.\\n\\nUsers working with chat models will usually access information via either\\n`AIMessage` (returned from runnable interfaces) or `LLMResult` (available\\nvia callbacks).',\n",
       "   'properties': {'text': {'default': '', 'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Generation Info'},\n",
       "    'type': {'const': 'ChatGeneration',\n",
       "     'default': 'ChatGeneration',\n",
       "     'enum': ['ChatGeneration'],\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'message': {'$ref': '#/$defs/BaseMessage'}},\n",
       "   'required': ['message'],\n",
       "   'title': 'ChatGeneration',\n",
       "   'type': 'object'},\n",
       "  'ChatGenerationChunk': {'description': 'ChatGeneration chunk, which can be concatenated with other\\nChatGeneration chunks.',\n",
       "   'properties': {'text': {'default': '', 'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Generation Info'},\n",
       "    'type': {'const': 'ChatGenerationChunk',\n",
       "     'default': 'ChatGenerationChunk',\n",
       "     'enum': ['ChatGenerationChunk'],\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'message': {'$ref': '#/$defs/BaseMessageChunk'}},\n",
       "   'required': ['message'],\n",
       "   'title': 'ChatGenerationChunk',\n",
       "   'type': 'object'},\n",
       "  'Generation': {'description': 'A single text generation output.\\n\\nGeneration represents the response from an \"old-fashioned\" LLM that\\ngenerates regular text (not chat messages).\\n\\nThis model is used internally by chat model and will eventually\\nbe mapped to a more general `LLMResult` object, and then projected into\\nan `AIMessage` object.\\n\\nLangChain users working with chat models will usually access information via\\n`AIMessage` (returned from runnable interfaces) or `LLMResult` (available\\nvia callbacks). Please refer the `AIMessage` and `LLMResult` schema documentation\\nfor more information.',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Generation Info'},\n",
       "    'type': {'const': 'Generation',\n",
       "     'default': 'Generation',\n",
       "     'enum': ['Generation'],\n",
       "     'title': 'Type',\n",
       "     'type': 'string'}},\n",
       "   'required': ['text'],\n",
       "   'title': 'Generation',\n",
       "   'type': 'object'},\n",
       "  'GenerationChunk': {'description': 'Generation chunk, which can be concatenated with other Generation chunks.',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Generation Info'},\n",
       "    'type': {'const': 'Generation',\n",
       "     'default': 'Generation',\n",
       "     'enum': ['Generation'],\n",
       "     'title': 'Type',\n",
       "     'type': 'string'}},\n",
       "   'required': ['text'],\n",
       "   'title': 'GenerationChunk',\n",
       "   'type': 'object'},\n",
       "  'RunInfo': {'description': 'Class that contains metadata for a single execution of a Chain or model.\\n\\nDefined for backwards compatibility with older versions of langchain_core.\\n\\nThis model will likely be deprecated in the future.\\n\\nUsers can acquire the run_id information from callbacks or via run_id\\ninformation present in the astream_event API (depending on the use case).',\n",
       "   'properties': {'run_id': {'format': 'uuid',\n",
       "     'title': 'Run Id',\n",
       "     'type': 'string'}},\n",
       "   'required': ['run_id'],\n",
       "   'title': 'RunInfo',\n",
       "   'type': 'object'}},\n",
       " 'description': 'A container for results of an LLM call.\\n\\nBoth chat models and LLMs generate an LLMResult object. This object contains\\nthe generated outputs and any additional information that the model provider\\nwants to return.',\n",
       " 'properties': {'generations': {'items': {'items': {'anyOf': [{'$ref': '#/$defs/Generation'},\n",
       "      {'$ref': '#/$defs/ChatGeneration'},\n",
       "      {'$ref': '#/$defs/GenerationChunk'},\n",
       "      {'$ref': '#/$defs/ChatGenerationChunk'}]},\n",
       "    'type': 'array'},\n",
       "   'title': 'Generations',\n",
       "   'type': 'array'},\n",
       "  'llm_output': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'title': 'Llm Output'},\n",
       "  'run': {'anyOf': [{'items': {'$ref': '#/$defs/RunInfo'}, 'type': 'array'},\n",
       "    {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'title': 'Run'},\n",
       "  'type': {'const': 'LLMResult',\n",
       "   'default': 'LLMResult',\n",
       "   'enum': ['LLMResult'],\n",
       "   'title': 'Type',\n",
       "   'type': 'string'}},\n",
       " 'required': ['generations'],\n",
       " 'title': 'LLMResult',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets generate a full output with mmore information\n",
    "result = llm.generate([\"Here is Fun Fact about Pluto : \",\n",
    "                       \"Here is a Fun Fact about Mars :\"])\n",
    "\n",
    "# to check the schema of the response\n",
    "result.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Pluto was discovered in 1930 by astronomer Clyde Tombaugh and was initially classified as the ninth planet in our solar system. However, in 2006, it was reclassified as a dwarf planet due to its small size and different characteristics from the other eight planets.\n"
     ]
    }
   ],
   "source": [
    "# Check the detailed response\n",
    "response = result.generations\n",
    "print(response[0][0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'total_tokens': 118,\n",
       "  'completion_tokens': 102,\n",
       "  'prompt_tokens': 16},\n",
       " 'model_name': 'gpt-3.5-turbo-instruct'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the token usage and other details about output of the LLM\n",
    "\n",
    "result.llm_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "chat = ChatOpenAI(openai_api_key = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! One interesting fact about Earth is that it is the only known planet in our solar system that has liquid water on its surface, which is essential for supporting life as we know it.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 16, 'total_tokens': 55, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-dec832c3-c24b-4532-b6fc-96b2e25de649-0', usage_metadata={'input_tokens': 16, 'output_tokens': 39, 'total_tokens': 55})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets ask a question\n",
    "result = chat.invoke([HumanMessage(content=\"Can you tell me a fact about Earth ?\")])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! One interesting fact about Earth is that it is the only known planet in our solar system that has liquid water on its surface, which is essential for supporting life as we know it.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the text response\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Of course! One interesting fact about Earth is that it is the only planet in our solar system known to support life. Its unique combination of atmosphere, water, and moderate temperatures have allowed for the development and sustenance of a wide variety of living organisms.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets try another\n",
    "result = chat.generate([[SystemMessage(content=\"You are a University Professor\"),\n",
    "                         HumanMessage(content=\"Can you tell me a fact about Earth ?\")]])\n",
    "\n",
    "result.generations[0][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Temperature is a parameter that controls the “creativity” or randomness of the text generated by open ai llm. A higher temperature (e.g., 0.7) results in more diverse and creative output, while a lower temperature (e.g., 0.2) makes the output more deterministic and focused.\n",
    "\n",
    "- In practice, temperature affects the probability distribution over the possible tokens at each step of the generation process. A temperature of 0 would make the model completely deterministic, always choosing the most likely token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One interesting fact about Earth is that Earth is the only planet in our solar system where water can exist in liquid form on its surface, which is essential for all known forms of life.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can add some extra parameters and args - here we are adding some extreme values\n",
    "result = chat.invoke([HumanMessage(content=\"Can you tell me a fact about Earth ?\")],\n",
    "                     temperature=2, max_tokens=100)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching\n",
    "\n",
    "Should only do this if the prompt is the exact same and the historical replies are okay to return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "# Initialize the cache\n",
    "langchain.llm_cache = InMemoryCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Mars is the fourth planet from the Sun and is known as the \"Red Planet\" due to its reddish appearance.\n",
      "\n",
      "2. It is the second smallest planet in our solar system, with a diameter of about half the size of Earth's.\n",
      "\n",
      "3. Mars has a thin atmosphere consisting mainly of carbon dioxide, with traces of nitrogen and argon.\n",
      "\n",
      "4. The planet has the largest volcano in the solar system, Olympus Mons, which stands at over 21 km high and has a diameter of 600 km.\n",
      "\n",
      "5. Mars also has the largest canyon in the solar system, Valles Marineris, which is over 4,000 km long and up to 7 km deep.\n",
      "\n",
      "6. The planet has two small, icy polar ice caps made of water and carbon dioxide.\n",
      "\n",
      "7. Mars has two small moons, Phobos and Deimos, which are irregularly shaped and are thought to be captured asteroids.\n",
      "\n",
      "8. The average surface temperature on Mars is -80°F (-62°C), but it can reach as high as 70°F (20°C) at the equator during the summer.\n",
      "\n",
      "9. There is evidence of liquid water on Mars in the past, indicating that the planet may have been capable of supporting life.\n",
      "\n",
      "10. NASA\n"
     ]
    }
   ],
   "source": [
    "# The first time it is not in cache and hence might take little time\n",
    "print(llm.invoke(\"Tell me fact about Mars\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Mars is the fourth planet from the Sun and is known as the \"Red Planet\" due to its reddish appearance.\n",
      "\n",
      "2. It is the second smallest planet in our solar system, with a diameter of about half the size of Earth's.\n",
      "\n",
      "3. Mars has a thin atmosphere consisting mainly of carbon dioxide, with traces of nitrogen and argon.\n",
      "\n",
      "4. The planet has the largest volcano in the solar system, Olympus Mons, which stands at over 21 km high and has a diameter of 600 km.\n",
      "\n",
      "5. Mars also has the largest canyon in the solar system, Valles Marineris, which is over 4,000 km long and up to 7 km deep.\n",
      "\n",
      "6. The planet has two small, icy polar ice caps made of water and carbon dioxide.\n",
      "\n",
      "7. Mars has two small moons, Phobos and Deimos, which are irregularly shaped and are thought to be captured asteroids.\n",
      "\n",
      "8. The average surface temperature on Mars is -80°F (-62°C), but it can reach as high as 70°F (20°C) at the equator during the summer.\n",
      "\n",
      "9. There is evidence of liquid water on Mars in the past, indicating that the planet may have been capable of supporting life.\n",
      "\n",
      "10. NASA\n"
     ]
    }
   ],
   "source": [
    "# This response should come very fast\n",
    "print(llm.invoke(\"Tell me fact about Mars\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
